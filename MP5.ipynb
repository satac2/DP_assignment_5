{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"MP5.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"cells":[{"cell_type":"markdown","metadata":{"id":"z2KdoWKsz6i1"},"source":["# Deep Q-Learning "]},{"cell_type":"markdown","metadata":{"id":"B-eHcpLtz6i_"},"source":["Install dependencies for AI gym to run properly (shouldn't take more than a minute). If running on google cloud or running locally, only need to run once. Colab may require installing everytime the vm shuts down."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kNCcOt620UfS","executionInfo":{"status":"ok","timestamp":1620063208981,"user_tz":300,"elapsed":482,"user":{"displayName":"Rob E","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPuhG9d5B6UDMjaKBuJr0scpJuPWvCFMt_p9rS=s64","userId":"04284816091903632090"}},"outputId":"f80e6b0d-269f-4614-c59c-85d62d451e4f"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z_7eqMKF0f2E","executionInfo":{"status":"ok","timestamp":1620063210320,"user_tz":300,"elapsed":438,"user":{"displayName":"Rob E","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPuhG9d5B6UDMjaKBuJr0scpJuPWvCFMt_p9rS=s64","userId":"04284816091903632090"}},"outputId":"39ca9753-ea46-4c42-ff5f-98a69b02bede"},"source":["!ls\n","import os\n","os.chdir(\"drive/MyDrive/assignment5_materials\")"],"execution_count":2,"outputs":[{"output_type":"stream","text":["drive  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SYOUxVGGz6i_","executionInfo":{"status":"ok","timestamp":1620062632477,"user_tz":300,"elapsed":6407,"user":{"displayName":"Rob E","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPuhG9d5B6UDMjaKBuJr0scpJuPWvCFMt_p9rS=s64","userId":"04284816091903632090"}},"outputId":"fd63a3e1-a2d5-4b9d-c145-516e73aa05ef"},"source":["!pip3 install gym pyvirtualdisplay\n","!sudo apt-get install -y xvfb python-opengl ffmpeg"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (2.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym) (1.4.1)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym) (1.19.5)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.5.0)\n","Requirement already satisfied: EasyProcess in /usr/local/lib/python3.7/dist-packages (from pyvirtualdisplay) (0.3)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym) (0.16.0)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","python-opengl is already the newest version (3.1.0+dfsg-1).\n","ffmpeg is already the newest version (7:3.4.8-0ubuntu0.2).\n","xvfb is already the newest version (2:1.19.6-1ubuntu4.9).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'sudo apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ViZb8gjYz6jA","executionInfo":{"status":"ok","timestamp":1620060099194,"user_tz":300,"elapsed":18487,"user":{"displayName":"Rob E","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPuhG9d5B6UDMjaKBuJr0scpJuPWvCFMt_p9rS=s64","userId":"04284816091903632090"}},"outputId":"b9a36acb-d63a-45c8-d65e-8bc0ae3123b1"},"source":["!pip3 install --upgrade setuptools --user\n","!pip3 install ez_setup \n","!pip3 install gym[atari] "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: setuptools in /usr/local/lib/python3.7/dist-packages (56.0.0)\n","Collecting ez_setup\n","  Downloading https://files.pythonhosted.org/packages/ba/2c/743df41bd6b3298706dfe91b0c7ecdc47f2dc1a3104abeb6e9aa4a45fa5d/ez_setup-0.9.tar.gz\n","Building wheels for collected packages: ez-setup\n","  Building wheel for ez-setup (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ez-setup: filename=ez_setup-0.9-cp37-none-any.whl size=11014 sha256=f30fc577a397a42b9b5fded1eb51fddfc1e13907499feb12939faf32a185a9c9\n","  Stored in directory: /root/.cache/pip/wheels/dc/e8/6b/3d5ff5a3efd7b5338d1e173ac981771e2628ceb2f7866d49ad\n","Successfully built ez-setup\n","Installing collected packages: ez-setup\n","Successfully installed ez-setup-0.9\n","Requirement already satisfied: gym[atari] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.19.5)\n","Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.5.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.4.1)\n","Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (1.3.0)\n","Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (7.1.2)\n","Requirement already satisfied: atari-py~=0.2.0; extra == \"atari\" in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (0.2.6)\n","Requirement already satisfied: opencv-python; extra == \"atari\" in /usr/local/lib/python3.7/dist-packages (from gym[atari]) (4.1.2.30)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[atari]) (0.16.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from atari-py~=0.2.0; extra == \"atari\"->gym[atari]) (1.15.0)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hyNHTquUz6jA"},"source":["For this assignment we will implement the Deep Q-Learning algorithm with Experience Replay as described in breakthrough paper __\"Playing Atari with Deep Reinforcement Learning\"__. We will train an agent to play the famous game of __Breakout__."]},{"cell_type":"code","metadata":{"id":"v0GOHFH4z6jA","executionInfo":{"status":"ok","timestamp":1620063214472,"user_tz":300,"elapsed":1436,"user":{"displayName":"Rob E","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPuhG9d5B6UDMjaKBuJr0scpJuPWvCFMt_p9rS=s64","userId":"04284816091903632090"}}},"source":["%matplotlib inline\n","\n","import sys\n","import gym\n","import torch\n","import pylab\n","import random\n","import numpy as np\n","from collections import deque\n","from datetime import datetime\n","from copy import deepcopy\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","from utils import find_max_lives, check_live, get_frame, get_init_state\n","from model import DQN\n","from config import *\n","\n","import matplotlib.pyplot as plt\n","# %load_ext autoreload\n","# %autoreload 2"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aYTCiL-iz6jB"},"source":["## Understanding the environment"]},{"cell_type":"markdown","metadata":{"id":"MCRETxZlz6jB"},"source":["In the following cell, we initialize our game of __Breakout__ and you can see how the environment looks like. For further documentation of the of the environment refer to https://gym.openai.com/envs. \n","\n","In breakout, we will use 3 actions \"fire\", \"left\", and \"right\". \"fire\" is only used to reset the game when a life is lost, \"left\" moves the agent left and \"right\" moves the agent right."]},{"cell_type":"code","metadata":{"id":"YXnB-c_Dz6jC","executionInfo":{"status":"ok","timestamp":1620063216748,"user_tz":300,"elapsed":1109,"user":{"displayName":"Rob E","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPuhG9d5B6UDMjaKBuJr0scpJuPWvCFMt_p9rS=s64","userId":"04284816091903632090"}}},"source":["env = gym.make('BreakoutDeterministic-v4')\n","state = env.reset()"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"lRKS7UOOz6jC","executionInfo":{"status":"ok","timestamp":1620063216998,"user_tz":300,"elapsed":270,"user":{"displayName":"Rob E","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPuhG9d5B6UDMjaKBuJr0scpJuPWvCFMt_p9rS=s64","userId":"04284816091903632090"}}},"source":["number_lives = find_max_lives(env)\n","state_size = env.observation_space.shape\n","action_size = 3 #fire, left, and right"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-7zdEUrwz6jC"},"source":["## Creating a DQN Agent"]},{"cell_type":"markdown","metadata":{"id":"CV-hEM5uz6jD"},"source":["Here we create a DQN Agent. This agent is defined in the __agent.py__. The corresponding neural network is defined in the __model.py__. Once you've created a working DQN agent, use the code in agent.py to create a double DQN agent in __agent_double.py__. Set the flag \"double_dqn\" to True to train the double DQN agent.\n","\n","__Evaluation Reward__ : The average reward received in the past 100 episodes/games.\n","\n","__Frame__ : Number of frames processed in total.\n","\n","__Memory Size__ : The current size of the replay memory."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lpTxYIGPz6jD","executionInfo":{"status":"ok","timestamp":1620063221306,"user_tz":300,"elapsed":3389,"user":{"displayName":"Rob E","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPuhG9d5B6UDMjaKBuJr0scpJuPWvCFMt_p9rS=s64","userId":"04284816091903632090"}},"outputId":"313d0f21-5bbe-44c6-9160-fb219b65c973"},"source":["double_dqn = False # set to True if using double DQN agent\n","\n","if double_dqn:\n","    from agent_double import Agent\n","else:\n","    from agent import Agent\n","\n","agent = Agent(action_size)\n","evaluation_reward = deque(maxlen=evaluation_reward_length)\n","frame = 0\n","memory_size = 0"],"execution_count":6,"outputs":[{"output_type":"stream","text":["init\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"HMeJ5jCnz6jD"},"source":["### Main Training Loop"]},{"cell_type":"markdown","metadata":{"id":"S223xB18z6jD"},"source":["In this training loop, we do not render the screen because it slows down training signficantly. To watch the agent play the game, run the code in next section \"Visualize Agent Performance\""]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"774nHfwJz6jE","scrolled":true,"executionInfo":{"status":"error","timestamp":1620063223043,"user_tz":300,"elapsed":3166,"user":{"displayName":"Rob E","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPuhG9d5B6UDMjaKBuJr0scpJuPWvCFMt_p9rS=s64","userId":"04284816091903632090"}},"outputId":"5986973e-b64f-4f5e-c396-8fac00b2a73b"},"source":["rewards, episodes = [], []\n","best_eval_reward = 0\n","for e in range(EPISODES):\n","    done = False\n","    score = 0\n","\n","    history = np.zeros([5, 84, 84], dtype=np.uint8)\n","    step = 0\n","    d = False\n","    state = env.reset()\n","    next_state = state\n","    life = number_lives\n","\n","    get_init_state(history, state)\n","\n","    while not done:\n","        step += 1\n","        frame += 1\n","\n","        # Perform a fire action if ball is no longer on screen to continue onto next life\n","        if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n","            action = 0\n","        else:\n","            action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n","        state = next_state\n","        next_state, reward, done, info = env.step(action + 1)\n","        \n","        frame_next_state = get_frame(next_state)\n","        history[4, :, :] = frame_next_state\n","        terminal_state = check_live(life, info['ale.lives'])\n","\n","        life = info['ale.lives']\n","        r = np.clip(reward, -1, 1) \n","        r = reward\n","\n","        # Store the transition in memory \n","        agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n","        # Start training after random sample generation\n","\n","        if(frame >= train_frame):\n","            \n","            agent.train_policy_net(frame)\n","            # Update the target network only for Double DQN only\n","            if double_dqn and (frame % update_target_network_frequency)== 0:\n","                agent.update_target_net()\n","        score += reward\n","        history[:4, :, :] = history[1:, :, :]\n","            \n","        if done:\n","            evaluation_reward.append(score)\n","            rewards.append(np.mean(evaluation_reward))\n","            episodes.append(e)\n","            pylab.plot(episodes, rewards, 'b')\n","            pylab.xlabel('Episodes')\n","            pylab.ylabel('Rewards') \n","            pylab.title('Episodes vs Reward')\n","            pylab.savefig(\"./save_graph/breakout_dqn.png\") # save graph for training visualization\n","            \n","            # every episode, plot the play time\n","            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n","                  len(agent.memory), \"  epsilon:\", agent.epsilon, \"   steps:\", step,\n","                  \"   lr:\", agent.optimizer.param_groups[0]['lr'], \"    evaluation reward:\", np.mean(evaluation_reward))\n","\n","            # if the mean of scores of last 100 episode is bigger than 5 save model\n","            ### Change this save condition to whatever you prefer ###\n","            if np.mean(evaluation_reward) > 5 and np.mean(evaluation_reward) > best_eval_reward:\n","                torch.save(agent.policy_net, \"./save_model/breakout_dqn.pth\")\n","                best_eval_reward = np.mean(evaluation_reward)\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Get action\n","tensor([[2]], device='cuda:0')\n","Get action\n","tensor([[0]], device='cuda:0')\n","Get action\n","tensor([[1]], device='cuda:0')\n","Get action\n","tensor([[1]], device='cuda:0')\n","Get action\n","tensor([[1]], device='cuda:0')\n","Get action\n","tensor([[0]], device='cuda:0')\n","Get action\n","tensor([[2]], device='cuda:0')\n","Get action\n","tensor([[2]], device='cuda:0')\n","Get action\n","tensor([[1]], device='cuda:0')\n","Get action\n","tensor([[2]], device='cuda:0')\n","Get action\n","tensor([[2]], device='cuda:0')\n","Get action\n","tensor([[2]], device='cuda:0')\n","Get action\n","tensor([[1]], device='cuda:0')\n","Get action\n","tensor([[0]], device='cuda:0')\n","Get action\n","tensor([[1]], device='cuda:0')\n","Get action\n","tensor([[1]], device='cuda:0')\n","Get action\n","tensor([[2]], device='cuda:0')\n","Get action\n","tensor([[0]], device='cuda:0')\n","Get action\n","tensor([[1]], device='cuda:0')\n","Get action\n","tensor([[0]], device='cuda:0')\n","Get action\n","tensor([[0]], device='cuda:0')\n","Get action\n","tensor([[2]], device='cuda:0')\n","Get action\n","tensor([[2]], device='cuda:0')\n","Get action\n","tensor([[2]], device='cuda:0')\n","Get action\n","tensor([[2]], device='cuda:0')\n","Get action\n","tensor([[0]], device='cuda:0')\n","Get action\n","tensor([[0]], device='cuda:0')\n","Get action\n","tensor([[1]], device='cuda:0')\n","Get action\n","tensor([[1]], device='cuda:0')\n","Get action\n","tensor([[1]], device='cuda:0')\n","Get action\n","tensor([[2]], device='cuda:0')\n","Get action\n","tensor([[1]], device='cuda:0')\n","Get action\n","tensor([[2]], device='cuda:0')\n","Get action\n","tensor([[0]], device='cuda:0')\n","Get action\n","tensor([[0]], device='cuda:0')\n","Get action\n","tensor([[0]], device='cuda:0')\n","Frame:  50\n","Sample range:  45\n","after sampling mini_batch\n","Pre Q_curr\n","States size:  torch.Size([32, 4, 84, 84])\n","Histoery size:  (32, 5, 84, 84)\n","Actions size:  torch.Size([32, 1, 1, 1])\n"],"name":"stdout"},{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1pWnYlSSM6pEk4HY8WsSbD738k3L_xphq/assignment5_materials/memory.py:30: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  sample = np.array(sample)\n","/content/drive/.shortcut-targets-by-id/1pWnYlSSM6pEk4HY8WsSbD738k3L_xphq/assignment5_materials/agent.py:66: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n","  mini_batch = np.array(mini_batch).transpose()\n"],"name":"stderr"},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-16f5b84b2f85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mtrain_frame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_policy_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             \u001b[0;31m# Update the target network only for Double DQN only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdouble_dqn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mupdate_target_network_frequency\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/.shortcut-targets-by-id/1pWnYlSSM6pEk4HY8WsSbD738k3L_xphq/assignment5_materials/agent.py\u001b[0m in \u001b[0;36mtrain_policy_net\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Histoery size: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Actions size: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mQ_current\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as input tensor"]}]},{"cell_type":"markdown","metadata":{"id":"tI3AMrtkz6jF"},"source":["# Visualize Agent Performance"]},{"cell_type":"markdown","metadata":{"id":"xXU6Dc53z6jG"},"source":["BE AWARE THIS CODE BELOW MAY CRASH THE KERNEL IF YOU RUN THE SAME CELL TWICE.\n","\n","Please save your model before running this portion of the code."]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"xfxI_Y1Lz6jG"},"source":["torch.save(agent.policy_net, \"./save_model/breakout_dqn_latest.pth\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"background_save":true},"id":"T5xi5wEHz6jH"},"source":["from gym.wrappers import Monitor\n","import glob\n","import io\n","import base64\n","\n","from IPython.display import HTML\n","from IPython import display as ipythondisplay\n","\n","from pyvirtualdisplay import Display\n","\n","# Displaying the game live\n","def show_state(env, step=0, info=\"\"):\n","    plt.figure(3)\n","    plt.clf()\n","    plt.imshow(env.render(mode='rgb_array'))\n","    plt.title(\"%s | Step: %d %s\" % (\"Agent Playing\",step, info))\n","    plt.axis('off')\n","\n","    ipythondisplay.clear_output(wait=True)\n","    ipythondisplay.display(plt.gcf())\n","    \n","# Recording the game and replaying the game afterwards\n","def show_video():\n","    mp4list = glob.glob('video/*.mp4')\n","    if len(mp4list) > 0:\n","        mp4 = mp4list[0]\n","        video = io.open(mp4, 'r+b').read()\n","        encoded = base64.b64encode(video)\n","        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","             </video>'''.format(encoded.decode('ascii'))))\n","    else: \n","        print(\"Could not find video\")\n","    \n","\n","def wrap_env(env):\n","    env = Monitor(env, './video', force=True)\n","    return env"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k09IAF_Oz6jH","outputId":"353669f5-cdf9-40bc-8c80-af0f0b1bda98"},"source":["display = Display(visible=0, size=(300, 200))\n","display.start()\n","\n","# Load agent\n","# agent.load_policy_net(\"./save_model/breakout_dqn.pth\")\n","agent.epsilon = 0.0 # Set agent to only exploit the best action\n","\n","env = gym.make('BreakoutDeterministic-v4')\n","env = wrap_env(env)\n","\n","done = False\n","score = 0\n","step = 0\n","state = env.reset()\n","next_state = state\n","life = number_lives\n","history = np.zeros([5, 84, 84], dtype=np.uint8)\n","get_init_state(history, state)\n","\n","while not done:\n","    \n","    # Render breakout\n","    env.render()\n","#     show_state(env,step) # uncommenting this provides another way to visualize the game\n","\n","    step += 1\n","    frame += 1\n","\n","    # Perform a fire action if ball is no longer on screen\n","    if step > 1 and len(np.unique(next_state[:189] == state[:189])) < 2:\n","        action = 0\n","    else:\n","        action = agent.get_action(np.float32(history[:4, :, :]) / 255.)\n","    state = next_state\n","    \n","    next_state, reward, done, info = env.step(action + 1)\n","        \n","    frame_next_state = get_frame(next_state)\n","    history[4, :, :] = frame_next_state\n","    terminal_state = check_live(life, info['ale.lives'])\n","        \n","    life = info['ale.lives']\n","    r = np.clip(reward, -1, 1) \n","    r = reward\n","\n","    # Store the transition in memory \n","    agent.memory.push(deepcopy(frame_next_state), action, r, terminal_state)\n","    # Start training after random sample generation\n","    score += reward\n","    \n","    history[:4, :, :] = history[1:, :, :]\n","env.close()\n","show_video()\n","display.stop()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<video alt=\"test\" autoplay \n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n","             </video>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["<pyvirtualdisplay.display.Display at 0x7f705e9b28d0>"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"CVMhvB77z6jI"},"source":[""],"execution_count":null,"outputs":[]}]}